{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish-Soni08/Playground/blob/main/haystack/Advent_of_Haystack_Pipeline_Connecting(Ashish_Soni).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advent of Haystack: Day 1\n",
        "\n",
        "\n",
        "In this first challenge, we are going to build a RAG pipeline that answers questions based on the contents of a URL. Most of the pipeline is ready, but your task is to complete the pipeline connections \n",
        "\n",
        "You should complete Step 5 of this colab.\n",
        "\n",
        "### Components to use:\n",
        "1. `LinkContentFetcher`: Expects a list of URLs and returns `ByteStream` type\n",
        "2. `HTMLToDocument`: Expects a `ByteStream` and creates `Document` type.\n",
        "3. `DocumentSplitter`: This expects a list of `Documents` and returns a list of split, preprocessed documents.\n",
        "4. `PromptBuilder`: To define the manner we want to interact with an LLM. We use Jinja templating\n",
        "5. `GPTGenerator`: Expects a fully formed prompt and queries an OpenAI GPT model."
      ],
      "metadata": {
        "id": "5q2FHwPY-wqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Installation\n",
        "\n",
        "**Note:** There is a known issue with colab due to a version conflict error related to `llmx` which comes with Colab. You might get an `llmx` error. You can safely ignore this, or run `pip uninstall -y llmx`"
      ],
      "metadata": {
        "id": "ZALZDx-LFebK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJJ5AT3Z79e3"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install haystack-ai\n",
        "!pip install boilerpy3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Enter API keys for LLM and search providers\n",
        "Run this code and youll be prompted to enter your OpenAI API Key. If you dont have a key, [follow these instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key)."
      ],
      "metadata": {
        "id": "W3jwS4A_FmEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Enter OpenAI API key:\")"
      ],
      "metadata": {
        "id": "zy4xBS6v8n1s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb35a91-5d58-4808-88a0-5df75fef2607"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Create components"
      ],
      "metadata": {
        "id": "85pAAbaPFtZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.generators import GPTGenerator\n",
        "\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = HTMLToDocument()\n",
        "splitter = DocumentSplitter(split_length=100, split_overlap=5)"
      ],
      "metadata": {
        "id": "oXMwKWzUAEaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Given the information below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            Question: {{ query }}. \\n Answer:\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template = template)"
      ],
      "metadata": {
        "id": "qI4OaTHBa-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GPTGenerator(api_key = openai_api_key, model_name = \"gpt-3.5-turbo-1106\")"
      ],
      "metadata": {
        "id": "98SZvedobVKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Add them to a Haystack 2.0 Pipeline"
      ],
      "metadata": {
        "id": "jnDhrfD5AayG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component(name=\"fetcher\", instance=fetcher)\n",
        "pipeline.add_component(name=\"converter\", instance=converter)\n",
        "pipeline.add_component(name=\"splitter\", instance=splitter)\n",
        "pipeline.add_component(name=\"prompt_builder\", instance=prompt_builder)\n",
        "pipeline.add_component(name=\"llm\", instance=llm)"
      ],
      "metadata": {
        "id": "UIXUQWG5AYg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5) Connect the components\n",
        "\n",
        "Complete the pipelne connections to achieve a working pipeline that can be run\n",
        "\n",
        "**PSA:** If you are re-running this cell multiple times and you get a `PipelineConnectionError`, try restarting your Colab runtime."
      ],
      "metadata": {
        "id": "KFQOOQkaAeRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.connect(\"fetcher\", \"converter\")\n",
        "pipeline.connect(\"converter\", \"splitter\")\n",
        "pipeline.connect(\"splitter\", \"prompt_builder.documents\")\n",
        "pipeline.connect(\"prompt_builder\", \"llm\")"
      ],
      "metadata": {
        "id": "hpDVUIhlAi0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6) Run the Pipeline"
      ],
      "metadata": {
        "id": "Y2v6GZs6Am5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_dict ={\n",
        "    \"urls\": [\"https://haystack.deepset.ai/blog/customizing-rag-to-summarize-hacker-news-posts-with-haystack2\"],\n",
        "    \"query\": \"How do you build a custom component?\"\n",
        "}\n",
        "\n",
        "\n",
        "result = pipeline.run(data={\"fetcher\": {\"urls\": query_dict[\"urls\"]}, \"prompt_builder\": {\"query\": query_dict[\"query\"]}})"
      ],
      "metadata": {
        "id": "Gbo1QwM9Ambj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['llm']['replies'][0])"
      ],
      "metadata": {
        "id": "daLZtg3gb7m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41d4911d-71c1-4d30-b4a1-41ec00212a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To build a custom component in Haystack 2.0, you need to follow these steps:\n",
            "\n",
            "1. Create a class that does one specific task.\n",
            "2. Add a @component decorator on the class declaration to indicate that it is a Haystack component.\n",
            "3. Define a run function with a @component.output_types decorator that describes the output the pipeline should expect from the component.\n",
            "\n",
            "For example, you could create a custom component that fetches data from a specific source, processes the data, or performs any other specialized task. You would then mark this class as a component with the @component decorator and define the run function with the necessary output types using the @component.output_types decorator.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7) Draw the Pipeline \n",
        "When you run this code block, it will create a new file that will appear in the \"Files\" section of Colab (see menu tab on the side)."
      ],
      "metadata": {
        "id": "z0eEFSDYAjOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.draw(\"/content/pipeline_day_1.png\")"
      ],
      "metadata": {
        "id": "ctE6bDESAqv8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
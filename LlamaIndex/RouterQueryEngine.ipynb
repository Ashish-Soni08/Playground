{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish-Soni08/Playground/blob/main/LlamaIndex/RouterQueryEngine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Router Query Engine"
      ],
      "metadata": {
        "id": "D1Y3gSVdHdzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this tutorial, we will be using a router query engine, which will choose one of multiple candidate query engines to execute user query.\n",
        "\n",
        "[Documentation](https://gpt-index.readthedocs.io/en/stable/examples/query_engine/RouterQueryEngine.html)"
      ],
      "metadata": {
        "id": "fuAwUKiCCkze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "vlLzNfQrC54i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "\n",
        "!pip install llama-index"
      ],
      "metadata": {
        "id": "uOZ6iXTJHlQ5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: This is ONLY necessary in jupyter notebook.\n",
        "# Details: Jupyter runs an event-loop behind the scenes.\n",
        "#          This results in nested event-loops when we start an event-loop to make async queries.\n",
        "#          This is normally not allowed, we use nest_asyncio to allow it for convenience.\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "R_Ttz5WDI8M6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LGEOh3sdFuQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41f8758e-8d78-4cf0-8d05-1071ae0eeb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "# Set up the root logger\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)  # Set logger level to INFO\n",
        "\n",
        "# Clear out any existing handlers\n",
        "logger.handlers = []\n",
        "\n",
        "# Set up the StreamHandler to output to sys.stdout (Colab's output)\n",
        "handler = logging.StreamHandler(sys.stdout)\n",
        "handler.setLevel(logging.INFO)  # Set handler level to INFO\n",
        "\n",
        "# Add the handler to the logger\n",
        "logger.addHandler(handler)\n",
        "\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SummaryIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    ServiceContext,\n",
        "    StorageContext,\n",
        ")\n",
        "\n",
        "import openai\n",
        "openai.api_key = '' # OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Data"
      ],
      "metadata": {
        "id": "igDWYnajC_tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0ePCxRKDIXl",
        "outputId": "0848b212-5a03-4382-cd63-d1f7d04fe904"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 07:15:12--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75042 (73K) [text/plain]\n",
            "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
            "\n",
            "\r          data/paul   0%[                    ]       0  --.-KB/s               \rdata/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-28 07:15:12 (6.04 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "l0Cp38vaDGbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
      ],
      "metadata": {
        "id": "7UuQpLoRD1Wp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define List Index and Vector Index over Same Data"
      ],
      "metadata": {
        "id": "e4LNrmhrK4xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_index = SummaryIndex.from_documents(documents)\n",
        "vector_index = VectorStoreIndex.from_documents(documents)"
      ],
      "metadata": {
        "id": "B9C2Gm1UF8r3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3844c6d3-5276-47d6-c12e-4abcd519bd2f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Query Engines and Set Metadata"
      ],
      "metadata": {
        "id": "voktqsQNLApj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\",\n",
        "    use_async=True,\n",
        ")\n",
        "vector_query_engine = vector_index.as_query_engine()"
      ],
      "metadata": {
        "id": "uLMKbMAUGA9f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.tools.query_engine import QueryEngineTool\n",
        "\n",
        "\n",
        "summary_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=summary_query_engine,\n",
        "    description=\"Useful for summarization questions related to Paul Graham eassy on What I Worked On.\",\n",
        ")\n",
        "\n",
        "vector_tool = QueryEngineTool.from_defaults(\n",
        "    query_engine=vector_query_engine,\n",
        "    description=\"Useful for retrieving specific context from Paul Graham essay on What I Worked On.\",\n",
        ")"
      ],
      "metadata": {
        "id": "fg4aOwPaGNxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Router Query Engine\n",
        "\n",
        "There are several selectors available, each with some distinct attributes.\n",
        "\n",
        "The LLM selectors use the LLM to output a JSON that is parsed, and the corresponding indexes are queried.\n",
        "\n",
        "The Pydantic selectors (currently only supported by gpt-4-0613 and gpt-3.5-turbo-0613 (the default)) use the OpenAI Function Call API to produce pydantic selection objects, rather than parsing raw JSON.\n",
        "\n",
        "For each type of selector, there is also the option to select 1 index to route to, or multiple."
      ],
      "metadata": {
        "id": "F0zHAQS_LF3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PydanticSingleSelector"
      ],
      "metadata": {
        "id": "jTncjEj2LH88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.query_engine.router_query_engine import RouterQueryEngine\n",
        "from llama_index.selectors.llm_selectors import LLMSingleSelector\n",
        "from llama_index.selectors.pydantic_selectors import (\n",
        "    PydanticSingleSelector,\n",
        ")\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "\n",
        "query_engine = RouterQueryEngine(\n",
        "    selector=PydanticSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "GGjl2y5QGRcW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")"
      ],
      "metadata": {
        "id": "0hywia-DGTx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e42d7f1-9926-4b56-a45a-4f94e525d336"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting query engine 0: This choice is specifically mentioned as useful for summarization questions..\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1404 request_id=419cd57a9e440da0873dc3a4c25509d6 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2909 request_id=82b561c67a80b84b2ba6efe745e1adf5 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2978 request_id=1239b5027e18fded0f7deabefac9db0a response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3335 request_id=52f70f1da08abbc83b6c091509ff85f0 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3471 request_id=ae26eba0fa1c432dad1cb8673cbc40b3 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3606 request_id=c3627fac718e12b55fb21440dc9fbe33 response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "sriu-0zoLR7q",
        "outputId": "c71abbef-a00b-4a15-9251-2e1f926211a6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The document provides a personal account of the author's experiences and interests in writing, programming, art, and entrepreneurship. It covers their early experiences in writing and programming, their fascination with artificial intelligence, their transition to microcomputers, and their decision to focus on Lisp programming. The document also discusses the author's experiences as an art student, their observations about painting still lives, and their decision to drop out of art school and start a company called Viaweb. It further explores the challenges and successes of building an online store builder, the importance of high production values, and the lessons learned from running a startup. The document also touches on the author's involvement in various projects related to publishing essays online and starting an investment firm called Y Combinator. It concludes with the author reflecting on their past choices and considering future endeavors.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLMSingleSelector"
      ],
      "metadata": {
        "id": "5zkEOzNYLUQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = RouterQueryEngine(\n",
        "    selector=LLMSingleSelector.from_defaults(),\n",
        "    query_engine_tools=[\n",
        "        summary_tool,\n",
        "        vector_tool,\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "TbnqXGG-Ga3B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What is the summary of the document?\")"
      ],
      "metadata": {
        "id": "d_xrq9gYGdf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a7e81c-cde6-4ff9-e0b2-73e11c7b59c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting query engine 0: The first choice is relevant because it mentions summarization questions related to the essay..\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1701 request_id=49b35c1309404eccea074ffc6b395829 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3012 request_id=ac6e67c0b8cc7b1e07e781b52fbeb1a7 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=2982 request_id=8bfd187e56388ac13a5a27986a07c869 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3855 request_id=ebae114951855e021463266940ec8f75 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3366 request_id=37b0a853e1721bde4f1ba7d455ca6b25 response_code=200\n",
            "message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3592 request_id=c87433994da5fbbedf6373803bf3b7dc response_code=200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "id": "ksusZylqG_Nb",
        "outputId": "490d9a1e-735f-46f8-cb4f-c48ecce8884a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">The document provides a personal account of the author's experiences and decisions throughout their career. It begins with their early experiences in writing and programming, their fascination with artificial intelligence, and their transition to microcomputers. The author also shares their decision to pursue art and their experiences at art school. The document then discusses the author's involvement in starting a company called Viaweb, the challenges they faced in the early days of the internet, and their realization of the potential of web applications. The author reflects on their decision to leave Viaweb and pursue painting, as well as their involvement in various projects such as publishing essays online and starting an investment firm. The document concludes with the author reflecting on their past choices and contemplating future endeavors.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"What did Paul Graham do after RICS?\")"
      ],
      "metadata": {
        "id": "IEfQDl8LGd8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6c84c5-89fb-4400-c15f-abe55365e4b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting query engine 1: The question is asking for specific context about what Paul Graham did after RICS, which is better suited for retrieving specific context from the essay..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(HTML(f'<p style=\"font-size:20px\">{response.response}</p>'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "S1DXw_KxHApd",
        "outputId": "93cdb9e6-b53a-4a3f-e435-a83769743580"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"font-size:20px\">After RICS, Paul Graham applied to art schools and was accepted into the BFA program at RISD. He then went on to attend art classes at Harvard and eventually became an artist.</p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}